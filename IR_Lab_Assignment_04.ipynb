{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " # Analyze word frequency and distributions.\n",
        "   #    â€¢    Use Markov models or GPT-based libraries to generate text."
      ],
      "metadata": {
        "id": "kuWVyaWxEwuS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFXVf360EjYf",
        "outputId": "bfa8fdaa-a3b1-464c-f50c-3861c6d95109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "import nltk\n",
        "import random\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d0 ='This is a simple example, which is used in this lab'\n",
        "d1 = ' This example shows term frequency'\n",
        "d2 ='This example also shows text generation'\n",
        "string = [d0, d1, d2]"
      ],
      "metadata": {
        "id": "tFNz8A73FAy_"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in string:\n",
        "  tokens = nltk.word_tokenize(i.lower())\n",
        "  fdist = nltk.FreqDist(tokens)\n",
        "  print(dict(fdist))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHUxdNCOHpf6",
        "outputId": "aeac2e53-7c99-4e74-fe61-512a2e9db418"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'this': 2, 'is': 2, 'a': 1, 'simple': 1, 'example': 1, ',': 1, 'which': 1, 'used': 1, 'in': 1, 'lab': 1}\n",
            "{'this': 1, 'example': 1, 'shows': 1, 'term': 1, 'frequency': 1}\n",
            "{'this': 1, 'example': 1, 'also': 1, 'shows': 1, 'text': 1, 'generation': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer()\n",
        "result = tfidf.fit_transform(string)"
      ],
      "metadata": {
        "id": "qwG0KDQVF2EU"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word, index in tfidf.vocabulary_.items():\n",
        "    print(f\"{word}: {result[0, index]:.4f}, {result[1, index]:.4f}, {result[2, index]:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3PfJ2oCGqKF",
        "outputId": "4277e776-fa15-4786-e1d1-5900b3e4f10f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this: 0.3604, 0.3263, 0.2856\n",
            "is: 0.6102, 0.0000, 0.0000\n",
            "simple: 0.3051, 0.0000, 0.0000\n",
            "example: 0.1802, 0.3263, 0.2856\n",
            "which: 0.3051, 0.0000, 0.0000\n",
            "used: 0.3051, 0.0000, 0.0000\n",
            "in: 0.3051, 0.0000, 0.0000\n",
            "lab: 0.3051, 0.0000, 0.0000\n",
            "shows: 0.0000, 0.4202, 0.3678\n",
            "term: 0.0000, 0.5525, 0.0000\n",
            "frequency: 0.0000, 0.5525, 0.0000\n",
            "also: 0.0000, 0.0000, 0.4836\n",
            "text: 0.0000, 0.0000, 0.4836\n",
            "generation: 0.0000, 0.0000, 0.4836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#   Use Markov models or GPT-based libraries to generate text."
      ],
      "metadata": {
        "id": "1HuQFgE7SXYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk.util import ngrams\n",
        "\n",
        "\n",
        "def generate_markov_text(text, size=20):\n",
        "    words = word_tokenize(text)\n",
        "    if len(words) < 2:\n",
        "        return \"Input text is too short to generate Markov text.\"\n",
        "\n",
        "    markov_chain = {}\n",
        "\n",
        "    # Create n-grams (bigrams in this case)\n",
        "    for w1, w2 in ngrams(words, 2):\n",
        "        if w1 in markov_chain:\n",
        "            markov_chain[w1].append(w2)\n",
        "        else:\n",
        "            markov_chain[w1] = [w2]\n",
        "\n",
        "    # Start with a random word\n",
        "    word = random.choice(words)\n",
        "    result = [word]\n",
        "\n",
        "    for _ in range(size - 1):\n",
        "        next_words = markov_chain.get(word, [])\n",
        "        if next_words:\n",
        "            word = random.choice(next_words)\n",
        "            result.append(word)\n",
        "        else:\n",
        "            break  # Stop if no next word is found\n",
        "\n",
        "    return ' '.join(result)\n",
        "\n",
        "# Example usage\n",
        "text = \"This is a simple example of a Markov chain. A Markov chain is a stochastic model describing a sequence of possible events.\"\n",
        "print(\"\\nGenerated Text:\")\n",
        "print(generate_markov_text(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kQcdqpsIe2L",
        "outputId": "45735670-2d77-4616-c176-a53ede607cf2"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Text:\n",
            "of a stochastic model describing a stochastic model describing a stochastic model describing a stochastic model describing a sequence of\n"
          ]
        }
      ]
    }
  ]
}